{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a2fbe9-1ddb-45c6-aeb9-105773d0a24d",
   "metadata": {},
   "source": [
    "# Augmentation Pipeline\n",
    "\n",
    "Pipeline to generate augmented images and corresponding labels based on oriented bounding boxes in YOLO-format. So far, it only deals with single-class object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c1267-5046-420f-a569-8343d20ad5ae",
   "metadata": {},
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d452e-e417-4fcb-9bca-8740590850aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#automatically reload any imported modules when you re-run a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e71277-456f-4fd7-85bd-3da5b1c0d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2220496-e6c7-4043-8e1a-39107dbb0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./exmaple_data\" ##folder to data\n",
    "aug_suffix = \"aug\" ##suffix for data-saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e392665-26fb-4168-9604-980505784c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_id = 'example1_000001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db477fc6-7b06-4023-9abd-4ef49e0b0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_and_label_paths(data_dir, image_id):\n",
    "    \"\"\" Returns dictionary with image file path and label file path for a given image_id.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: string\n",
    "        path to dataset, e.g. \"/home/user/fisheye_data/\"\n",
    "    image_id: string\n",
    "        image identifier, e.g. \"ownrec1_000001\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        image_path and label_path\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If image_id has invalid format.\n",
    "    FileNotFoundError\n",
    "        If image or label file does not exist. \n",
    "    \"\"\"\n",
    "    match = re.match(r'(.+)_\\d{6}(?:_\\d{3})?$', image_id)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid image_id format: {image_id}\")\n",
    "    subset_dir = match.group(1)\n",
    "\n",
    "    # Image path (check both jpg, PNG and png)\n",
    "    for ext in ['.jpg', '.PNG', '.png']:\n",
    "        image_path = os.path.join(data_dir, 'images', subset_dir, f'{image_id}{ext}')\n",
    "        if os.path.exists(image_path):\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Image file not found for {image_id} in {data_dir}/images/{subset_dir}\")\n",
    "\n",
    "    # Label path\n",
    "    label_path = os.path.join(data_dir, 'labels', subset_dir, f'{image_id}.txt')\n",
    "    if not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(f\"Label file not found for {image_id} in {label_path}\")\n",
    "\n",
    "    return {'image_path': image_path, 'label_path': label_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2160b7-9539-4eb3-9494-40bbd37f4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(image_path):\n",
    "    \"\"\" Returns height and width of image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path: string\n",
    "        path to image, e.g. \"/home/user/fisheye_data/images/dir1/dir1_0001.png\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int, int\n",
    "        height, width\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If image does not exist. \n",
    "    \"\"\"\n",
    "    if os.path.exists(image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        image_height, image_width = image.shape[:2]\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Image file not found in {image_path}\")\n",
    "    return image_height, image_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd69d2-a5b8-4832-9696-69f2dea36905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_bbox_from_file(label_path, image_height, image_width):\n",
    "    \"\"\" Load bounding boxes from label file and scale them to image dimensions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label_path: string\n",
    "        path to label-file, e.g. \"/home/user/fisheye_data/labels/dir1/dir1_0001.txt\"\n",
    "    image_height: int\n",
    "        height of image in pixels\n",
    "    image_widht: int\n",
    "        width of image in pixels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of list of tuple\n",
    "        list of bounding boxes; each bounding box is a list of four (x, y) coordinates: [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n",
    "        \n",
    "    \"\"\"\n",
    "    bboxes = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            coords = list(map(float, line.split()[1:]))  # Extract x1, y1, ..., x4, y4\n",
    "            keypoints = [(int(coords[i] * image_width), int(coords[i + 1] * image_height)) for i in range(0, 8, 2)] #scale from normalized coordinates to image dimensions \n",
    "            bboxes.append(keypoints)            \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4def9-6dbc-4939-81d9-c30a007d34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_with_bbox(image_array, bboxes, show=True):\n",
    "    \"\"\" Visualize a single image with overlaid OBB bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_array: np.ndarray\n",
    "        Image array (without bounding boxes drawn).\n",
    "    bboxes: list of list of tuple\n",
    "        list of bounding boxes; each bounding box is a list of four (x, y) coordinates\n",
    "    show : bool, optional\n",
    "        Whether to display the image plot. Default is True.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Image array with bounding boxes drawn.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If a bounding box has an unexpected shape.\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        coords = np.array(bbox)\n",
    "        if coords.shape!=(4,2):\n",
    "            raise ValueError(f'Bounding Box has wrong shape: {coords.shape}')\n",
    "        else:\n",
    "            cv2.polylines(image, [coords], isClosed=True, color=(0, 255, 255), thickness=3)\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab51b3-f844-4868-9030-ffef4adc6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_ids(data_dir, image_ids):\n",
    "    \"\"\" Visualize a collage of single or multiple image_ids.\n",
    "    Only works, if images and labels are saved!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: string\n",
    "        path to dataset, e.g. \"/home/user/fisheye_data/\"\n",
    "    image_ids: list\n",
    "        List of image_ids.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    no returns\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_images = len(image_ids)\n",
    "    columns = min(4, num_images)  # limit max columns to avoid tiny subplots\n",
    "    rows = math.ceil(num_images / columns)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(2 * columns, 2 * rows))\n",
    "    axs = axs.flatten() if num_images > 1 else [axs]\n",
    "    \n",
    "    for i, image_id in enumerate(image_ids):\n",
    "        paths = get_image_and_label_paths(data_dir, image_id)\n",
    "        image_path = paths[\"image_path\"]\n",
    "        label_path = paths[\"label_path\"]\n",
    "    \n",
    "        h, w = get_image_size(image_path)\n",
    "        bboxes = scaled_bbox_from_file(label_path, h, w)\n",
    "    \n",
    "        image = cv2.imread(image_path)\n",
    "        image = visualize_image_with_bbox(image, bboxes, show=False)\n",
    "    \n",
    "        axs[i].imshow(image)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(image_id, fontsize=7)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2cb52-c32a-4079-98b1-7ca2ded3bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(image_array, bboxes, transform):\n",
    "    \"\"\" Transforms image and bounding box.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_array: np.ndarray\n",
    "        Image array of original image.\n",
    "    bboxes: list of list of tuple\n",
    "        list of bounding boxes; each bounding box is a list of four (x, y) coordinates\n",
    "    transform: albumentations.core.composition.Compose\n",
    "        Compose of Albumentations transformations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Image array of transformed image.\n",
    "    np.ndarray\n",
    "        Array of transformed bounding boxes.\n",
    "\n",
    "    \"\"\"  \n",
    "    # Load and flatten keypoints\n",
    "    keypoints_flat = list(chain.from_iterable(bboxes))\n",
    "\n",
    "    # Apply augmentations\n",
    "    transformed = transform(image=image_array, keypoints=keypoints_flat)\n",
    "    transformed_image = transformed[\"image\"]\n",
    "    transformed_keypoints = transformed[\"keypoints\"]\n",
    "    \n",
    "    # Re-group keypoints into 4-point polygons\n",
    "    regrouped_keypoints = [transformed_keypoints[i:i + 4] for i in range(0, len(transformed_keypoints), 4)]\n",
    "    transformed_bboxes = [np.array(box, dtype=np.int32).reshape((4, 2)) for box in regrouped_keypoints]\n",
    "    \n",
    "    return transformed_image, transformed_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37111899-1478-4a47-8fed-4ab284262e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo_obb(bboxes, image_height,  image_width, class_id=0):\n",
    "    \"\"\" Normalize bounding box coordinates for YOLO-OBB format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bboxes: np.ndarray\n",
    "        Array of bounding boxes coordinates.\n",
    "    image_height: int\n",
    "        height of image in pixels\n",
    "    image_widht: int\n",
    "        width of image in pixels\n",
    "    class_id: int, optional\n",
    "        Class label for all bounding boxes. Default is 0.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        List with one string per line for a yolo-obb-format txt-label file.    \n",
    "    \"\"\"\n",
    "    yolo_obb_lines = []\n",
    "    \n",
    "    for box in bboxes:\n",
    "        normalized_points = []\n",
    "        for x, y in box:\n",
    "            x_norm = x / image_width\n",
    "            y_norm = y / image_height\n",
    "            normalized_points.extend([x_norm, y_norm])\n",
    "            \n",
    "        yolo_line = f\"{class_id} \" + \" \".join(f\"{coord:.6f}\" for coord in normalized_points)\n",
    "        yolo_obb_lines.append(yolo_line)\n",
    "\n",
    "    return yolo_obb_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2698ff-ee7b-4a85-947d-c9513d1f2779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_augmented_image_and_label(data_dir, aug_suffix, image_id, transformation_index, transformed_image, yolo_obb_lines):\n",
    "    \"\"\"\n",
    "    Saves an augmented image and label-file to a corresponding directory for augmented files and return information about these files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: string\n",
    "        path to dataset, e.g. \"/home/user/fisheye_data/\"\n",
    "    aug_suffix: string\n",
    "        suffix for direcotry and file names\n",
    "    image_id: string\n",
    "        image identifier, e.g. \"ownrec1_000001\"\n",
    "    transformation_index: int\n",
    "        index of transformation of this single image\n",
    "    transformed_image: np.ndarray\n",
    "        Image array of original image.\n",
    "    yolo_obb_lines: list of strings\n",
    "        List with one string per line for a yolo-obb-format txt-label file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "     dict\n",
    "        new image_id, image_path and label_path\n",
    "    \"\"\"\n",
    "    # Extract subset name from image_id (e.g. 'ownrec1' from 'ownrec1_000001')\n",
    "    match = re.match(r'(.+?)_\\d{6}$', image_id)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid image_id format: {image_id}\")\n",
    "    subset_name = match.group(1)\n",
    "    augmented_subset = f\"{subset_name}_{aug_suffix}\"\n",
    "\n",
    "    # Create new image_id\n",
    "    new_image_id = f\"{augmented_subset}_{image_id[-6:]}_{transformation_index:03}\"\n",
    "\n",
    "    # Save image\n",
    "    image_output_dir = os.path.join(data_dir, \"images\", augmented_subset)\n",
    "    os.makedirs(image_output_dir, exist_ok=True)\n",
    "    image_path = os.path.join(image_output_dir, f\"{new_image_id}.PNG\")\n",
    "    #Image.fromarray(transformed_image).save(image_path)\n",
    "    cv2.imwrite(image_path, transformed_image)\n",
    "    \n",
    "    # Save label\n",
    "    label_output_dir = os.path.join(data_dir, \"labels\", augmented_subset)\n",
    "    os.makedirs(label_output_dir, exist_ok=True)\n",
    "    label_path = os.path.join(label_output_dir, f\"{new_image_id}.txt\")\n",
    "    with open(label_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(yolo_obb_lines))\n",
    "\n",
    "    return {'image_id': new_image_id, 'image_path': image_path, 'label_path': label_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef3d00f-2b84-4fb1-8407-f02efbaaa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_saving_pipeline(data_dir, aug_suffix, image_id, number_transformations, transform):\n",
    "    \"\"\"\n",
    "    Full augmentation pipeline including saving for a single image_id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: string\n",
    "        path to dataset, e.g. \"/home/user/fisheye_data/\"\n",
    "    aug_suffix: string\n",
    "        suffix for direcotry and file names\n",
    "    image_id: string\n",
    "        image identifier, e.g. \"ownrec1_000001\"\n",
    "    number_transformations: int\n",
    "        number of transformation to execute\n",
    "    transform: albumentations.core.composition.Compose\n",
    "        Compose of Albumentations transformations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     list\n",
    "        list of strings with new image_id's\n",
    "    \"\"\"\n",
    "    paths = get_image_and_label_paths(data_dir=data_dir, image_id=image_id)\n",
    "    image_path = paths[\"image_path\"]\n",
    "    label_path = paths[\"label_path\"]\n",
    "    \n",
    "    image_array = cv2.imread(image_path)\n",
    "    h, w = get_image_size(image_path)\n",
    "    bboxes = scaled_bbox_from_file(label_path, h, w)\n",
    "    \n",
    "    transformed_ids = []\n",
    "    for i in range(number_transformations):\n",
    "        transformed_image, transformed_bboxes = apply_transformation(image_array, bboxes, transform)\n",
    "        transformed_height, transformed_width, _ = transformed_image.shape\n",
    "        yolo_obb_lines = convert_to_yolo_obb(bboxes=transformed_bboxes, image_height=transformed_height, image_width=transformed_width)\n",
    "        transformed_id = save_augmented_image_and_label(data_dir=data_dir, aug_suffix=aug_suffix, image_id=image_id, transformation_index=i, transformed_image=transformed_image, yolo_obb_lines=yolo_obb_lines)\n",
    "        transformed_ids.append(transformed_id['image_id'])\n",
    "    return transformed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb3c9a-603a-4596-a344-50bfc2179c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_image_ids(dirs, percentage):\n",
    "    \"\"\" Randomly selects a given percentage of images_ids from each directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dirs: list\n",
    "        list with strings to image-directories, e.g. \"/home/user/fisheye_data/images/ownrec1\"\n",
    "    percentage: int\n",
    "        percentage of all images in directories to select\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list of strings of randomly selected image_ids\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If percentage is not between 0 and 100.\n",
    "    FileNotFoundError\n",
    "        If one of the directories is not found, or if it has no image-file of the type PNG or JPEG.\n",
    "    \"\"\"\n",
    "    if not (0 < percentage <= 100):\n",
    "        raise ValueError(\"Percentage must be between 0 and 100.\")\n",
    "\n",
    "    selected_ids = []\n",
    "\n",
    "    for directory in dirs:\n",
    "        if not os.path.isdir(directory):\n",
    "            raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "        \n",
    "        # Collect files with all supported extensions\n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.PNG', '*.png']:\n",
    "            image_files.extend(glob(os.path.join(directory, ext)))\n",
    "\n",
    "        if not image_files:\n",
    "            raise FileNotFoundError(f\"No image files found in directory: {directory}\")\n",
    "            \n",
    "        # Extract image IDs without extension\n",
    "        image_ids = [os.path.splitext(os.path.basename(f))[0] for f in image_files]\n",
    "        \n",
    "        # Shuffle and select 50%\n",
    "        k = max(1, int(len(image_ids) * (percentage / 100.0)))\n",
    "        selected = random.sample(image_ids, k)\n",
    "        selected_ids.extend(selected)\n",
    "\n",
    "    return selected_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696bb11-eadd-46ee-9bcc-6ee98934767f",
   "metadata": {},
   "source": [
    "## Define Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992241a-d851-4a6d-9eca-573b32b04fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [  A.Resize(width=640, height=640),\n",
    "        ### Geometric Invariance\n",
    "        A.Resize(width=640, height=640),\n",
    "        A.Affine(scale=[1,1.2], rotate=[0,90], shear=0, translate_percent=0, keep_ratio=True, p=0.5),\n",
    "        A.Rotate(limit=90, p=1, border_mode=cv2.BORDER_CONSTANT), #border to be black       \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        \n",
    "        ### Occlusion\n",
    "        A.CoarseDropout(num_holes_range=(1, 8), hole_height_range=(0.1, 0.25),\n",
    "                    hole_width_range=(0.1, 0.25), fill_value=0, p=0.5),\n",
    "     \n",
    "        ### ChannelDropout/Greyscale\n",
    "        A.OneOf([\n",
    "            A.ToGray(p=1.0), # p=1.0 inside OneOf\n",
    "            A.ChannelDropout(p=1.0) # p=1.0 inside OneOf\n",
    "        ], p=0.2),\n",
    "        \n",
    "        ### Color Variation\n",
    "        A.OneOf([A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.8),            \n",
    "                 A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.8),            \n",
    "                 A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.8),            \n",
    "                 A.RandomGamma(gamma_limit=(80, 120), p=0.8),        \n",
    "                ], p=0.7),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False) #remove_invisible=False stellt sicher, dass auf keinem Fall Koordinaten verloren gehen und so die Reihenfolge korrekt bleibt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ffdf5-2f2c-414f-81bc-efd082b5867f",
   "metadata": {},
   "source": [
    "## Exmaple with single image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b3e2d-957a-4a50-8f0d-be93633b0246",
   "metadata": {},
   "source": [
    "### Load Example Image & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f287b87-f265-4d01-825c-36f8e70f8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image_ids(data_dir, [example_image_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1eae8-c134-40f5-854f-bd24555f90ca",
   "metadata": {},
   "source": [
    "### Apply augmentation one time and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6c9c6-6245-437c-bdd6-e53e649348f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get paths for image_id\n",
    "paths = get_image_and_label_paths(data_dir=data_dir, image_id=example_image_id)\n",
    "example_image_path = paths[\"image_path\"]\n",
    "example_label_path = paths[\"label_path\"]\n",
    "\n",
    "# Read image as array and bboxes\n",
    "image_array = cv2.imread(example_image_path)\n",
    "h, w = get_image_size(example_image_path) #needed to scale bbox\n",
    "bboxes = scaled_bbox_from_file(example_label_path, h, w)\n",
    "\n",
    "# Apply transformation\n",
    "transformed_image, transformed_bboxes = apply_transformation(image_array, bboxes, transform)\n",
    "\n",
    "# Visualize\n",
    "visualize_image_with_bbox(transformed_image, transformed_bboxes, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289efee-0bcc-4957-82f2-69aa0394035c",
   "metadata": {},
   "source": [
    "### Apply augmentation multiple times and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e423f4-cf0c-4a5a-9621-86e1d1983080",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "columns = 6\n",
    "rows = 3\n",
    "\n",
    "# Plot original image.\n",
    "img = visualize_image_with_bbox(image_array, bboxes, show=False)\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "for i in tqdm(range(2, columns*rows+1)):\n",
    "    #transform image multiple times\n",
    "    transformed_image, transformed_bboxes = apply_transformation(image_array, bboxes, transform)\n",
    "    img = visualize_image_with_bbox(transformed_image, transformed_bboxes, show=False)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('tranformation-samples.png', bbox_inches='tight')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7d1e6-193e-4e38-86ed-886754bd6e72",
   "metadata": {},
   "source": [
    "## Pipeline: Single Image Id (Augmentation + Saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979490d-5054-4b04-b434-afd7c3d7a403",
   "metadata": {},
   "source": [
    "### Visualize Saved Images & Labels\n",
    "The images and labels are loaded again from disk, where they were saved in the step before. The visualization is to double check, that the saving worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20dd9bc-2e07-4c68-bb6a-f9af135e5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = augmentation_saving_pipeline(data_dir=data_dir, aug_suffix=aug_suffix, image_id=example_image_id, number_transformations=3, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b59db-e9c4-4924-8bf0-0f7f7e6a9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image_ids(data_dir, image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573f94f-c5ee-4740-9b51-fa3c9647cedd",
   "metadata": {},
   "source": [
    "## Pipeline: Multiple Image Ids\n",
    "\n",
    "We randomly select image_ids from a selection of directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a2cc0-be57-4b59-b9ca-f64730119c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [f'{data_dir}/images/example1', f'{data_dir}/images/example2'] #List with paths to the different subsets.\n",
    "random_ids = get_random_image_ids(dirs=dirs, percentage=100) #percentage of how many of all images from each subset to select (1-100)\n",
    "print(f'randomly selected {len(random_ids)} image_ids to transform now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e176021-2c23-42e7-ab22-e33fd42d92a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee180acd-9e17-4d3a-bdde-9ddf83e0487f",
   "metadata": {},
   "source": [
    "Now we use the full augmentation & saving pipeline to transform each of the randomly selected images a set number of times, save the resulting images and labels and record the image_ids of these transformed images to plot in the second step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa46cd1-84e8-49cf-8d66-5b35596f848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ids_plotlist = [] #new image_id's to plot later (hence the name \"plotlist\")\n",
    "for image_id in tqdm(random_ids):\n",
    "    transformed_ids = augmentation_saving_pipeline(data_dir=data_dir, aug_suffix=aug_suffix,\n",
    "                                                   image_id=image_id, \n",
    "                                                   number_transformations=3, transform=transform)\n",
    "    transformed_ids_plotlist.extend([image_id]) #include the original image_id as well as comparison in final plot\n",
    "    transformed_ids_plotlist.extend(transformed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a59d70-2832-4bec-af39-5734011f1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image_ids(data_dir, transformed_ids_plotlist[:4*4],) #save_path='a17_trainingsample.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d466fb-7181-4e9b-a148-9cf5acb602cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
